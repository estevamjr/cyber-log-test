Markdown

# üöÄ Processador de Logs de Partidas

## 1. Vis√£o Geral do Projeto
Esta √© uma aplica√ß√£o backend robusta, constru√≠da com NestJS (Node.js), projetada para ser uma solu√ß√£o completa no processamento e an√°lise de logs de partidas de jogos de tiro em primeira pessoa (FPS). [cite_start]üéÆ 

A API permite o upload de arquivos de log, processa os dados para extrair estat√≠sticas detalhadas de cada partida e dos jogadores, persiste esses relat√≥rios em um banco de dados PostgreSQL e exp√µe os resultados atrav√©s de m√∫ltiplos endpoints para consulta e an√°lise. √â ideal para integra√ß√£o com ferramentas de Business Intelligence (BI) ou frontends interativos. [cite_start]üìä 

O projeto foi desenvolvido com foco em Test-Driven Development (TDD), garantindo a qualidade e a corretude das regras de neg√≥cio. Isso inclui desde o c√°lculo de rankings por partida at√© a implementa√ß√£o de funcionalidades complexas como "kill streaks", "awards" (pr√™mios por desempenho) e a detec√ß√£o de "friendly fire". [cite_start]‚úÖ 

## 2. Tecnologias Utilizadas
Um olhar sobre as ferramentas que impulsionam este projeto:

* [cite_start]**Backend:** Node.js, NestJS 
* [cite_start]**Banco de Dados:** PostgreSQL (gerenciado via Supabase) üêò 
* [cite_start]**ORM:** TypeORM 
* [cite_start]**Testes:** Jest (para testes unit√°rios e E2E), Supertest 
* [cite_start]**Vari√°veis de Ambiente:** Dotenv 

## 3. Como Executar o Projeto
Siga estes passos para colocar a aplica√ß√£o em funcionamento em sua m√°quina local:

### Pr√©-requisitos
Certifique-se de ter instalado:

* [cite_start]Node.js (v18 ou superior) üü¢ 
* [cite_start]npm (gerenciador de pacotes do Node.js) 
* [cite_start]Uma inst√¢ncia de banco de dados PostgreSQL (local ou em nuvem como Supabase) 

### Passos para Instala√ß√£o
1.  **Clonar o reposit√≥rio:**
    ```bash
    git clone [URL_DO_SEU_REPOSITORIO]
    cd [NOME_DA_PASTA]
    ```

2.  **Instalar depend√™ncias:**
    ```bash
    npm install
    ```
    *Nota: Devido a conflitos em depend√™ncias de desenvolvimento, pode ser necess√°rio usar o comando `npm install --legacy-peer-deps`.*

3.  **Configurar Vari√°veis de Ambiente:**
    Crie um arquivo chamado `.env` na raiz do projeto e preencha com suas credenciais do banco de dados:
    ```env
    POSTGRES_HOST=seu_host_do_banco
    POSTGRES_PORT=5432
    POSTGRES_USER=seu_usuario
    POSTGRES_PASSWORD=sua_senha
    POSTGRES_DB=seu_banco
    ```

4.  **Iniciar a aplica√ß√£o em modo de desenvolvimento:**
    ```bash
    npm run start:dev
    ```
    O servidor estar√° dispon√≠vel em `http://localhost:3000`. üöÄ

### Rodando os Testes
Para garantir a integridade e a qualidade do c√≥digo, execute a su√≠te de testes unit√°rios e E2E:
```bash
npm test
4. Endpoints da API
Explore as funcionalidades da API atrav√©s dos seguintes endpoints. A documenta√ß√£o interativa (Swagger UI) estar√° dispon√≠vel em http://localhost:3000/api-docs ap√≥s a aplica√ß√£o ser iniciada. üìñ 


POST /logs/upload 


GET /logs/matches 


GET /logs/matches/:id 


GET /logs/ranking/global 


GET /logs/matches/mvp 

5. Documenta√ß√£o da API (Swagger)
Para uma documenta√ß√£o completa, o projeto inclui duas especifica√ß√µes no formato Swagger 2.0, que foram movidas para a pasta /docs para melhor organiza√ß√£o:

docs/mvpSwagger.json (Vers√£o Atual):
Este arquivo representa a API como ela est√° atualmente implementada e funcional no reposit√≥rio. Ele documenta todos os endpoints, par√¢metros e modelos de dados que foram desenvolvidos e testados. 

docs/roadmapSwagger.json (Vis√£o Futura):
Este arquivo serve como um documento de design t√©cnico, descrevendo a vis√£o para a evolu√ß√£o da API. Ele incorpora as melhorias planejadas no "Roadmap de Melhorias T√©cnicas", incluindo seguran√ßa OAuth 2.0, pagina√ß√£o e tratamento de erros detalhado. 

6. Decis√µes de Arquitetura
Este projeto foi cuidadosamente constru√≠do com base em princ√≠pios s√≥lidos de engenharia de software, visando a qualidade, manutenibilidade e testabilidade do c√≥digo. üèóÔ∏è 


Arquitetura em Camadas (SOLID): A aplica√ß√£o √© rigidamente dividida em camadas claras (Controller, Service, Repository), seguindo o Princ√≠pio da Responsabilidade √önica. 


Test-Driven Development (TDD): Todo o desenvolvimento da l√≥gica de neg√≥cio foi guiado por testes, com cobertura para testes unit√°rios e de ponta-a-ponta (E2E). 

Modelo de Dados Flex√≠vel: A decis√£o estrat√©gica de armazenar o relat√≥rio completo de cada partida em uma √∫nica coluna jsonb no PostgreSQL oferece uma flexibilidade not√°vel, permitindo a adi√ß√£o de novas m√©tricas sem a necessidade de migra√ß√µes complexas no esquema do banco. üîÑ 

7. Roadmap de Melhorias T√©cnicas
Como parte de uma vis√£o de produto cont√≠nua, foi elaborado um roadmap com os pr√≥ximos passos para elevar a qualidade e a robustez da aplica√ß√£o. üó∫Ô∏è 

Melhorias Planejadas

Refatora√ß√£o e Qualidade de C√≥digo: Quebrar o m√©todo _generateReportForMatch em fun√ß√µes menores e com responsabilidades √∫nicas. 

Infraestrutura e DevOps: Criar um Dockerfile e docker-compose.yml para padronizar os ambientes e configurar um workflow no GitHub Actions para automa√ß√£o de testes. üê≥ 


Evolu√ß√£o da Arquitetura de Dados (Microservi√ßos): Migrar da abordagem jsonb para um esquema de banco de dados relacional e normalizado para permitir consultas SQL complexas e eficientes. 

Robustez e Escalabilidade: Implementar pagina√ß√£o nos endpoints que retornam listas e adicionar √≠ndices estrat√©gicos no banco de dados. ‚ö° 

Seguran√ßa da API (OAuth 2.0): Proteger todos os endpoints utilizando um fluxo de autentica√ß√£o e autoriza√ß√£o robusto com Passport.js. üîí 

D√©bitos T√©cnicos Identificados
Atualiza√ß√£o de Depend√™ncias: Durante a instala√ß√£o com npm install, foram identificados diversos pacotes depreciados (eslint, glob, supertest, etc.). √â necess√°rio planejar a atualiza√ß√£o destes pacotes para vers√µes mais recentes e suportadas para garantir a seguran√ßa e a estabilidade do projeto a longo prazo.

#### Evolu√ß√£o da Arquitetura para Grande Escala (Big Data)
A arquitetura atual, com seu `LogService` atuando como orquestrador, √© ideal para um volume de dados na casa dos milh√µes de registros. No entanto, para escalar a solu√ß√£o para a casa dos **bilh√µes de registros**, seria necess√°ria uma mudan√ßa de paradigma, saindo do c√°lculo "on-the-fly" (em tempo real) para uma abordagem de **Processamento em Lote (Batch Processing)**.

A estrat√©gia para essa escala seria:

1.  **Pipeline de ETL (Extract, Transform, Load):** Implementar um processo em background, utilizando ferramentas open source como **Apache Spark**, que rodaria periodicamente (ex: de hora em hora).
2.  **Separa√ß√£o de Bancos (OLTP e OLAP):**
    * Manter o **PostgreSQL** como nosso banco transacional (OLTP), otimizado para a escrita r√°pida dos relat√≥rios de partidas individuais.
    * O pipeline de ETL leria os dados do PostgreSQL, realizaria as agrega√ß√µes massivas (como o ranking global) e salvaria os resultados j√° consolidados em um **banco de dados anal√≠tico (OLAP)**, otimizado para leitura, como o **ClickHouse** ou **Apache Druid**.
3.  **Consumo Otimizado:** A API deixaria de calcular os rankings. Em vez disso, faria uma consulta simples e extremamente r√°pida ao banco anal√≠tico (OLAP) para buscar os dados j√° pr√©-calculados, entregando a resposta ao usu√°rio em milissegundos, independentemente do volume de dados processado em background.

Esta abordagem garante que a experi√™ncia do usu√°rio permane√ßa perform√°tica, movendo o custo computacional do processamento pesado para uma infraestrutura de dados ass√≠ncrona e dedicada.